{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseaux de Neurones Récurrents\n",
    "\n",
    "Nous avons vu précédement un modèle avec un Réseau de Neurones Denses ou entièrement connectés (perceptrons multicouches - MPL).\n",
    "\n",
    "Étudions à présent l'efficacité d'un modèle avec un Réseau de Neurones Récurrents (RNNs)\n",
    "\n",
    "Les RNNs sont conçus pour gérer des séquences de données, comme le texte ou les séries temporelles. Ils ont la capacité unique de maintenir un \"état\" ou une mémoire des entrées antérieures dans leur état interne, ce qui les rend idéaux pour les tâches où le contexte séquentiel est important. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Deg  Mo    GO  CO  CR    P1  PW       T3P  T1  Ready  Temps\n",
      "0    0   2  52.6  34  36  1.02  43  392.4298  39      1   5571\n",
      "1    0   2  52.4  33  36  0.98  43  385.4558  39      1   5572\n",
      "2    0   2  51.4  34  36  1.02  43  392.4298  40      1   5573\n",
      "3    0   2  51.3  33  36  1.00  42  385.4558  41      1   5574\n",
      "4    0   2  53.5  35  38  1.02  45  399.8960  41      1   5575\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamincordebar/.pyenv/versions/3.12.2/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.0398 - val_loss: 0.0103\n",
      "Epoch 2/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 3/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 4/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 5/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0088\n",
      "Epoch 6/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 7/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 8/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0082\n",
      "Epoch 9/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0093\n",
      "Epoch 10/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0077\n",
      "Epoch 11/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 12/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 13/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0078\n",
      "Epoch 14/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 15/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 16/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0084\n",
      "Epoch 17/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0074\n",
      "Epoch 18/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 19/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 20/20\n",
      "\u001b[1m1057/1057\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "\u001b[1m453/453\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Mean Squared Error (MSE): 0.007980104019878734\n",
      "Root Mean Squared Error (RMSE): 0.08933142795163825\n",
      "R-squared (Coefficient of Determination): 0.8148460161106368\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Chargement des données\n",
    "# Chemin vers le fichier Excel\n",
    "file_path = '/Users/benjamincordebar/Desktop/2A/S8/EP/Projet/EP/donnees_propres_2.xlsx'\n",
    "\n",
    "# Chargement du fichier\n",
    "try:\n",
    "    data = pd.read_excel(file_path)\n",
    "    print(data.head())  # Afficher les premières lignes pour inspecter les données\n",
    "except Exception as e:\n",
    "    print(\"Erreur lors du chargement du fichier:\", e)\n",
    "\n",
    "features = data[['CO', 'Mo', 'CR', 'Deg', 'Temps']]\n",
    "target = data['P1']\n",
    "\n",
    "# Fonction pour vérifier si la normalisation est nécessaire\n",
    "def needs_normalization(data, expected_min=0, expected_max=1):\n",
    "    actual_min, actual_max = np.min(data), np.max(data)\n",
    "    return actual_min < expected_min or actual_max > expected_max\n",
    "\n",
    "# Normaliser les données si nécessaire\n",
    "if needs_normalization(features):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    features = scaler.fit_transform(features)\n",
    "else:\n",
    "    features = features.values\n",
    "\n",
    "# Fonction pour créer des séquences pour l'entraînement du RNN\n",
    "def create_sequences(features, target, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - sequence_length):\n",
    "        X.append(features[i:(i + sequence_length)])\n",
    "        y.append(target[i + sequence_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sequence_length = 5  # Définir la longueur de la séquence selon votre choix\n",
    "X, y = create_sequences(features, target, sequence_length)\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Construction du modèle RNN avec LSTM\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(sequence_length, X_train.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Prédiction et évaluation du modèle\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calcul des métriques\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "r_squared = r2_score(y_test, predictions)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-squared (Coefficient of Determination):\", r_squared)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons constater : \n",
    "-  De très bon résultat !\n",
    "\n",
    "Nous avons utilisé dans ce Réseau de Neurones Récurrents, la fonction d'activation ReLU, or, dans le modèle précédent (MLP) nous avions trouvé que LeakyReLU était la mieux adaptée à notre problème. \n",
    "\n",
    "#### Essayons la fonction d'activation LeakyReLU avec ce modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Deg  Mo    GO  CO  CR    P1  PW       T3P  T1  Ready  Temps\n",
      "0    0   2  52.6  34  36  1.02  43  392.4298  39      1   5571\n",
      "1    0   2  52.4  33  36  0.98  43  385.4558  39      1   5572\n",
      "2    0   2  51.4  34  36  1.02  43  392.4298  40      1   5573\n",
      "3    0   2  51.3  33  36  1.00  42  385.4558  41      1   5574\n",
      "4    0   2  53.5  35  38  1.02  45  399.8960  41      1   5575\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjamincordebar/.pyenv/versions/3.12.2/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Users/benjamincordebar/.pyenv/versions/3.12.2/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.0345 - val_loss: 0.0112\n",
      "Epoch 2/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 3/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 4/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0085\n",
      "Epoch 5/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0088\n",
      "Epoch 6/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0081\n",
      "Epoch 7/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 8/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0078\n",
      "Epoch 9/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 10/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 11/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 12/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 13/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0085\n",
      "Epoch 14/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0080\n",
      "Epoch 15/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 16/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0077\n",
      "Epoch 17/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0075\n",
      "Epoch 18/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0075\n",
      "Epoch 19/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 20/20\n",
      "\u001b[1m1208/1208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0076\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Mean Squared Error (MSE): 0.00763377563435682\n",
      "Root Mean Squared Error (RMSE): 0.0873714806693627\n",
      "R-squared (Coefficient of Determination): 0.8239708208096543\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, LeakyReLU\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Chargement des données\n",
    "# Chemin vers le fichier Excel\n",
    "file_path = '/Users/benjamincordebar/Desktop/2A/S8/EP/Projet/EP/donnees_propres_2.xlsx'\n",
    "\n",
    "# Chargement du fichier\n",
    "try:\n",
    "    data = pd.read_excel(file_path)\n",
    "    print(data.head())  # Afficher les premières lignes pour inspecter les données\n",
    "except Exception as e:\n",
    "    print(\"Erreur lors du chargement du fichier:\", e)\n",
    "\n",
    "features = data[['CO', 'Mo', 'CR', 'Deg', 'Temps']]\n",
    "target = data['P1']\n",
    "\n",
    "# Fonction pour vérifier si la normalisation est nécessaire\n",
    "def needs_normalization(data, expected_min=0, expected_max=1):\n",
    "    actual_min, actual_max = np.min(data), np.max(data)\n",
    "    return actual_min < expected_min or actual_max > expected_max\n",
    "\n",
    "# Normaliser les données si nécessaire\n",
    "if needs_normalization(features):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    features = scaler.fit_transform(features)\n",
    "else:\n",
    "    features = features.values\n",
    "\n",
    "# Fonction pour créer des séquences pour l'entraînement du RNN\n",
    "def create_sequences(features, target, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - sequence_length):\n",
    "        X.append(features[i:(i + sequence_length)])\n",
    "        y.append(target[i + sequence_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sequence_length = 5  # Définir la longueur de la séquence selon votre choix\n",
    "X, y = create_sequences(features, target, sequence_length)\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construction du modèle RNN avec LSTM et LeakyReLU\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(sequence_length, X_train.shape[2]), return_sequences=True))\n",
    "model.add(LeakyReLU(alpha=0.01)) # alpha est le paramètre de pente\n",
    "model.add(LSTM(50))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entraînement du modèle\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Prédiction et évaluation du modèle\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calcul des métriques\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "r_squared = r2_score(y_test, predictions)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-squared (Coefficient of Determination):\", r_squared)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons constater : \n",
    "- une très légère amélioration. Cela est sûrement du au fait que malgré que se soit la fonction d'activation la plus adaptée, elle ne marche pas aussi bien qu'attendu en raison du faible nombre des données d'entraînement. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
